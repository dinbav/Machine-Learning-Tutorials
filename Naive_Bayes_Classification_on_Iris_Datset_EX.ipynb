{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Naive Bayes Classification on Iris Datset EX.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dinbav/Machine-Learning-Tutorials/blob/main/Naive_Bayes_Classification_on_Iris_Datset_EX.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vxOsyr691EM7"
      },
      "source": [
        "# Naive Bayes (NB) Classification (using scikit-learn) on Iris dataset.\n",
        "### Building a model to classify and predict the species of Iris flower based on the sepal length, speal width, petal length and petal width\n",
        "\n",
        "\n",
        "![alt text](https://res.cloudinary.com/dyd911kmh/image/upload/f_auto,q_auto:best/v1543836882/image_3_ijznzs.png)\n",
        "\n",
        "###please follow [this tutorial](https://www.datacamp.com/community/tutorials/naive-bayes-scikit-learn) and implement here. \n",
        "Detailed documentation on Naive Bayes Classification is available [here](https://scikit-learn.org/stable/modules/naive_bayes.html).\n",
        "\n",
        "In this exercise will implement Naive Bayes Classification on iris dataset using scikit-learn library. Iris dataset has 50 samples for each different species of Iris flower(total of 150). For each sample we have sepal length, width and petal length and width and a species name(class/label).\n",
        "\n",
        "\n",
        "Your task is to build a Naive Bayes Classification model which classifies the new species based on the sepal and petal measurements. Iris dataset is available in scikit-learn and we can make use of it build our Naive Bayes Classification."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iWgABDSsZ-2i"
      },
      "source": [
        "###Step1: Import the required data and check the features.\n",
        "Import the load_iris function form scikit-learen datasets module and create a iris Bunch object(bunch is a scikitlearn’s special object type for storing datasets and its attributes).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LibhfGaA1ENE"
      },
      "source": [
        "## Load the Iris data set and check the features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "exN_RwOO1ENF"
      },
      "source": [
        "#Import the load_iris function from datsets module\n",
        "#import load_iris from sklearn.datasets\n",
        "#your code here"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mOY3Wt2L1ENI"
      },
      "source": [
        "#Create bunch object containing iris dataset and its attributes.\n",
        "iris = load_iris()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xrpJgw2BaG8R"
      },
      "source": [
        "####Exploring Data\n",
        "You can print the target and feature names, to make sure you have the right dataset, as such:\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m0qvReKaaQBx"
      },
      "source": [
        "Each observation represents one flower and 4 columns represents 4 measurements.We can see the features(measures) under ‘data’ attribute, where as labels under ‘features_names’. As we can see below, labels/responses are encoded as 0,1 and 2. Because the features and repose should be numeric (Numpy arrays) for scikit-learn models and they should have a specific shape.\n",
        "\n",
        "### Feel free to explore the data as you wish as you did on the KNN EX"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fNiLYd-C1ENU"
      },
      "source": [
        "#Names of 4 features (column names)\n",
        "#your code here"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y9XZFguQ1ENY"
      },
      "source": [
        "#Integers representing the species: 0 = setosa, 1=versicolor, 2=virginica\n",
        "#your code here"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MoGSbc6OagzO"
      },
      "source": [
        "Let's check records of the target set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iMjwetMo1ENb"
      },
      "source": [
        "# 3 classes of target\n",
        "#your code here\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BDkNANkN1ENf",
        "outputId": "59dd21ad-f347-4a7e-8c35-4104c417f482",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "print(type(iris.data))\n",
        "print(type(iris.target))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "skGCLUYrapzj"
      },
      "source": [
        "check the shape of the dataset using shape.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "99J-Xb3Y1ENj",
        "outputId": "9e88874a-825f-43ab-c5a9-36d6b191727a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# we have a total of 150 observations and 4 features\n",
        "print(iris.data.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(150, 4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AarA9B-B1ENm"
      },
      "source": [
        "# Feature matrix in a object named X\n",
        "X = iris.data\n",
        "# response vector in a object named y\n",
        "y = iris.target"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4VIX4wxI1ENr",
        "outputId": "3b7db8d3-44ac-474b-8711-f0b22d733498",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "print(X.shape)\n",
        "print(y.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(150, 4)\n",
            "(150,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cJPoqTDF1ENv"
      },
      "source": [
        "# Train the Model "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ze4AGalBavWL"
      },
      "source": [
        "###Step 2: Split the data and Train the Model.\n",
        "First, you separate the columns into dependent and independent variables(or features and label). Then you split those variables into train and test set.\n",
        "\n",
        "\n",
        "\n",
        "![alt text](https://res.cloudinary.com/dyd911kmh/image/upload/f_auto,q_auto:best/v1543836883/image_6_cfpjpr.png)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "og9Ei02q1ENw",
        "outputId": "0be58a8e-db8e-4c3e-e35e-8b5d444cb1cf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 163
        }
      },
      "source": [
        "# splitting the data into training and test sets (80:20)\n",
        "# Import train_test_split function \n",
        "#your code here\n",
        "__________________ = ______________(X,y,test_size=_____,random_state=4) # 80% training and 20% test"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-f1447b7e1c83>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0m__________________\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m______________\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_____\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# 80% training and 20% test\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name '______________' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FYEbtycE1ENy",
        "outputId": "b770cf4f-ccde-482c-fe84-9058aa8a4eb8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 180
        }
      },
      "source": [
        "#shape of train and test objects\n",
        "print(X_train._____)\n",
        "print(______.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-07a3a7fba310>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_____\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m______\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'X_train' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6W89isoi1EN0",
        "outputId": "93cb90e2-4538-4717-eb04-6b7d5e028218",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 180
        }
      },
      "source": [
        "# shape of new y objects\n",
        "print(______.shape)\n",
        "print(y_test._______)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-3d43af85d36b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m______\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_______\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name '______' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b8YnJpI4c_8G"
      },
      "source": [
        "###Model Generation\n",
        "After splitting, you will generate a random forest model on the training set and perform prediction on test set features."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-kKveMWe1EN2"
      },
      "source": [
        "#Import Gaussian Naive Bayes model\n",
        "\n",
        "\n",
        "#Create a Gaussian Classifier\n",
        "\n",
        "\n",
        "#Train the model using the training sets\n",
        "\n",
        "\n",
        "#Predict the response for test dataset\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D2L4DKWGc4FU"
      },
      "source": [
        "####Evaluating Model\n",
        "After model generation, check the accuracy using actual and predicted values."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1hx_tV7h1EN4"
      },
      "source": [
        "#Import scikit-learn metrics module for accuracy calculation\n",
        "\n",
        "\n",
        "# Model Accuracy, how often is the classifier correct?\n",
        "#print(\"Accuracy:\"________________)\n",
        "#your code here"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WWqfzPArenqO"
      },
      "source": [
        "##Making Predictions\n",
        "Here we will value expected VS predicted results "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NyI2u5-NenT7"
      },
      "source": [
        "gnb.fit(iris.data, iris.target)\n",
        "\n",
        "expected = iris.target\n",
        "predicted = gnb.predict(iris.data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a7CrqBr3ffhD"
      },
      "source": [
        "###Getting Accuracy and Statistics\n",
        "Here we will create a classification report that contains the various statistics required to judge a model. After that, we will create a confusion matrix which will give us a clear idea of the accuracy and the fitting of the model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ydVsHA4Sf0yj"
      },
      "source": [
        "####Classification Report:\n",
        "for more info you can look[ here](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.classification_report.html)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fQy_hhIffkl0"
      },
      "source": [
        "# print classification_report for expected & predicted\n",
        "#your code here"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rdJd-KgjfuUd"
      },
      "source": [
        "####Confusion Matrix:\n",
        "for more info you can see [documentation](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html) or [here ](https://towardsdatascience.com/understanding-confusion-matrix-a9ad42dcfd62)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rIt0n8pQfuyb"
      },
      "source": [
        "# print confusion_matrix for expected & predicted \n",
        "#your code here"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0oC_AzpMgV9t"
      },
      "source": [
        "##Please explain in hebrew as simple as can (for dummies) the following:\n",
        "\n",
        "\n",
        "\n",
        "1.   The results- and its meaning\n",
        "2.   NB Advantages\n",
        "1.   NB Disadvantages\n",
        "2.   Compare the NB model to the KNN model refer to the implementation in the iris data-set\n",
        "2.   Your Conclusion and feedback\n"
      ]
    }
  ]
}